{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ceb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Create  a file:\n",
    "col:\n",
    "product_name varchar(20),\n",
    "manufacturingcost decimal(5,2)\n",
    "\n",
    "For each product build record using python script.\n",
    "'iphon11','iphone12','iphone13','iphoneSE','IpadMax','IpadMini','laptop256','Macbook512',\n",
    "'galaxy10','galaxy11','galaxy12','galaxy13','watch320','watch340'\n",
    "'Nk320',''Nk400',''Nk500'\n",
    "\n",
    "File example:\n",
    "iphon11,220\n",
    "iphone12,250\n",
    "iphone13,290\n",
    "\n",
    "\t# Language: Python\n",
    "\timport pandas as pd\n",
    "\n",
    "\n",
    "\tproduct_costs = {'iphone11': 800, 'iphone12': 900, 'iphone13': 950, 'iphoneSE': 700, 'IpadMax': 500, 'IpadMini': 400,\n",
    "\t\t\t\t\t 'laptop256': 1400, 'Macbook512': 1600, 'galaxy10': 800, 'galaxy11': 850, 'galaxy12': 875,\n",
    "\t\t\t\t\t 'galaxy13': 900, 'watch320': 249, 'watch340': 300, 'Nk320': 600, 'Nk400': 700, 'Nk500': 750}\n",
    "\tresult = []\n",
    "\tfor k, v in product_costs.items():\n",
    "\t\tresult.append((k, v))\n",
    "\n",
    "\tdf = pd.DataFrame(result, columns=['product', 'product_cost'])\n",
    "\tdf.to_csv('product_costs.csv', index=False)\n",
    "\n",
    "\n",
    "create a table in redshift also.-- table name product_cost\n",
    "\t\n",
    "\t-- Language Redshift SQL\n",
    "\tCreate table if not exists quantrix_schema.product_costs (\n",
    "\t   product varchar(20),\n",
    "\t   product_cost varchar(20),\n",
    "\t)\n",
    "\n",
    "2. Load data into s3 in separate folder (order data must be created earlier in class project 3).\n",
    "\n",
    "\t# Command Prompt using AWS CLI\n",
    "\t# Creating New Bucket\n",
    "\tC:\\Users\\User>aws s3 mb s3://NewBucket2 --region us-east-2\n",
    "\t\n",
    "\t# Loading CSV to New Bucket\n",
    "\tC:\\Users\\User>aws s3 cp \"C:\\filepath\\product_cost.csv\" s3://NewBucket2\n",
    "\n",
    "3. Use copy command  to load data into redshift by.\n",
    "\n",
    "\t-- Language Redshift SQL\n",
    "\tcopy quantrix_schema.product_costs from 's3://NewBucket2/product_costs.csv' \n",
    "\tiam_role 'arn:aws:iam::<USER>:role/<ROLE_NAME>'\n",
    "\tdelimiter ','\n",
    "\tignoreheader 1\n",
    "\n",
    "4  create a view by joining order and product_cost.\n",
    "\n",
    "\t-- Language Redshift SQL\n",
    "\tCREATE VIEW quantrix_schema.order_with_cost as(\n",
    "\tSELECT bd.*, pc.product_cost From quantrix_schema.big_data bd\n",
    "\tJOIN quantrix_schema.product_costs pc\n",
    "\tON bd.product_name = pc.product\n",
    "\t) WITH NO SCHEMA BINDING\n",
    "    \n",
    "5. Unload data from view into s3 bucket (this has to be separate bucket then created earlier)\n",
    "\n",
    "\t-- Language Redshift SQL\n",
    "\tUNLOAD ('SELECT * from quantrix_schema.order_with_cost')\n",
    "\tto 's3://quantrix-test-2/unload_results/'\n",
    "\tiam_role 'arn:aws:iam::<USER>:role/<ROLE_NAME>'\n",
    "\tcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4d50df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
