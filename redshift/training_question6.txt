1. Create  a file:
col:
product_name varchar(20),
manufacturingcost decimal(5,2)

For each product build record using python script.
'iphon11','iphone12','iphone13','iphoneSE','IpadMax','IpadMini','laptop256','Macbook512',
'galaxy10','galaxy11','galaxy12','galaxy13','watch320','watch340'
'Nk320',''Nk400',''Nk500'

File example:
iphon11,220
iphone12,250
iphone13,290

	# Language: Python
	import pandas as pd


	product_costs = {'iphone11': 800, 'iphone12': 900, 'iphone13': 950, 'iphoneSE': 700, 'IpadMax': 500, 'IpadMini': 400,
					 'laptop256': 1400, 'Macbook512': 1600, 'galaxy10': 800, 'galaxy11': 850, 'galaxy12': 875,
					 'galaxy13': 900, 'watch320': 249, 'watch340': 300, 'Nk320': 600, 'Nk400': 700, 'Nk500': 750}
	result = []
	for k, v in product_costs.items():
		result.append((k, v))

	df = pd.DataFrame(result, columns=['product', 'product_cost'])
	df.to_csv('product_costs.csv', index=False)


create a table in redshift also.-- table name product_cost
	
	-- Language Redshift SQL
	Create table if not exists quantrix_schema.product_costs (
	   product varchar(20),
	   product_cost varchar(20),
	)

2. Load data into s3 in separate folder (order data must be created earlier in class project 3).

	# Command Prompt using AWS CLI
	# Creating New Bucket
	
	C:\Users\User>aws s3 mb s3://NewBucket2 --region us-east-2
	
	# Loading CSV to New Bucket
	C:\Users\User>aws s3 cp "C:\filepath\product_cost.csv" s3://NewBucket2

3. Use copy command  to load data into redshift by.

	-- Language Redshift SQL
	copy quantrix_schema.product_costs from 's3://NewBucket2/product_costs.csv' 
	iam_role 'arn:aws:iam::<USER>:role/<ROLE_NAME>'
	delimiter ','
	ignoreheader 1

4  create a view by joining order and product_cost.

	-- Language Redshift SQL
	CREATE VIEW quantrix_schema.order_with_cost as(
	SELECT bd.*, pc.product_cost From quantrix_schema.big_data bd
	JOIN quantrix_schema.product_costs pc
	ON bd.product_name = pc.product
	) WITH NO SCHEMA BINDING

5. Unload data from view into s3 bucket (this has to be separate bucket then created earlier)

	-- Language Redshift SQL
	UNLOAD ('SELECT * from quantrix_schema.order_with_cost')
	to 's3://quantrix-test-2/unload_results/'
	iam_role 'arn:aws:iam::<USER>:role/<ROLE_NAME>'
	csv